{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3cb9639",
   "metadata": {},
   "outputs": [],
   "source": [
    "from final_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1b00bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining loss for the model\n",
    "MSE = tf.keras.losses.MeanSquaredError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8df9fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_inceptionresnet_multigap(input_shape=None, \n",
    "                                   return_sizes=False, model_path='models/quality-mlsp-mtl-mse-loss.hdf5'): # this are the pretrained optimal weights for the feature extractor\n",
    "    \"\"\"\n",
    "    Build InceptionResNetV2 multi-GAP model, that extracts narrow MLSP features.\n",
    "\n",
    "    :param input_shape: shape of the input images\n",
    "    :param return_sizes: return the sizes of each layer: (model, gap_sizes)\n",
    "    :return: model or (model, gap_sizes)\n",
    "    \"\"\"\n",
    "    model_base = InceptionResNetV2(weights='imagenet',\n",
    "                                  include_top=False,\n",
    "                                  input_shape=input_shape)\n",
    "\n",
    "    model_base.load_weights(model_path)\n",
    "\n",
    "    feature_layers = [l for l in model_base.layers if 'mixed' in l.name]\n",
    "    gaps = [GlobalAveragePooling2D(name=\"gap%d\" % i)(l.output)\n",
    "           for i, l in enumerate(feature_layers)]\n",
    "    concat_gaps = Concatenate(name='concatenated_gaps')(gaps)\n",
    "\n",
    "    x = Dense(2048, kernel_initializer='he_normal', activation='relu')(concat_gaps)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "    x = Dense(1024, kernel_initializer='he_normal', activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "    x = Dense(256, kernel_initializer='he_normal', activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    pred = Dense(2, activation='softmax')(x)\n",
    "    \n",
    "    model = Model(inputs=model_base.input, outputs=pred)\n",
    "\n",
    "    if return_sizes:\n",
    "        gap_sizes = [np.int32(g.get_shape()[1]) for g in gaps]\n",
    "        return (model, gap_sizes)\n",
    "    else:\n",
    "        return model\n",
    "\n",
    "\n",
    "def data_loader(data, h=100, w=100):\n",
    "    #big pictures require lots of computational data, so we resize them\n",
    "    imgs = []\n",
    "    skipped_image = []\n",
    "    for path in data:\n",
    "        try:\n",
    "            img = Image.open(path).convert('RGB')\n",
    "            img = img.resize((h, w), Image.Resampling.LANCZOS)\n",
    "            img_tensor = tf.keras.utils.img_to_array(img)\n",
    "            imgs.append(img_tensor)\n",
    "        except:\n",
    "            print('Skip')\n",
    "    \n",
    "#         if img.size > (1080,720):\n",
    "#             x = img_to_array(img)\n",
    "#             img.close()\n",
    "#             img = resize_main(x, size = (None, 512))\n",
    "\n",
    "    imgs = tf.stack(imgs, axis=0)\n",
    "    imgs = tf.squeeze(imgs)\n",
    "    \n",
    "    if imgs.shape[2] == 3:\n",
    "        imgs = imgs[None]\n",
    "\n",
    "    return imgs\n",
    "\n",
    "\n",
    "def trainer(model, data, weights_path, batch_size=32, epochs=30, learning_rate=0.03):\n",
    "    X_train, X_test, y_train, y_test = data\n",
    "   \n",
    "    X_train_loaded = data_loader(X_train, h=100, w=100)\n",
    "    X_test_loaded = data_loader(X_test, h=100, w=100)\n",
    "    data_val = (X_test_loaded, y_test)\n",
    "    print(f'{X_train_loaded.shape=}, {y_train.shape=}')\n",
    "    \n",
    "    model.load_weights(weights_path) \n",
    "\n",
    "    model.compile(loss=MSE,\n",
    "                  optimizer=keras.optimizers.Adam(learning_rate=learning_rate, beta_1=0.9, beta_2=0.999, \n",
    "                                              epsilon=1e-07, decay=0, amsgrad=False))\n",
    "\n",
    "    checkpoint = keras.callbacks.ModelCheckpoint(weights_path, \n",
    "                                                 monitor='val_loss', \n",
    "                                                 verbose=1, \n",
    "                                                 save_best_only=True, \n",
    "                                                 mode='min')\n",
    "\n",
    "    schedule = tf.keras.callbacks.LearningRateScheduler(scheduler, verbose=0)\n",
    "    callbacks_list = [checkpoint, schedule]\n",
    "\n",
    "    history = model.fit(X_train_loaded, y_train,\n",
    "                        batch_size=batch_size,\n",
    "                        epochs=epochs,\n",
    "                        verbose=0,\n",
    "                        callbacks=callbacks_list,\n",
    "                        validation_data = data_val)\n",
    "\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7022953",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choosing the number of image paths to read \n",
    "data_bad = np.array(glob('training-dataset/bad/*')[:1000])\n",
    "data_good = np.array(glob('training-dataset/good/*')[:1000])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4d008380",
   "metadata": {},
   "source": [
    "### Creating model, and loading weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfed6e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_inceptionresnet_multigap()\n",
    "weights_path = f'models/mg_dense_26_07.hdf5' \n",
    "# model.save_weights(weights_path) #if we want to cancel learning and start from 0\n",
    "model.load_weights(weights_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "568e82d0",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4adf6c10",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "epochs = 20\n",
    "\n",
    "histories = []\n",
    "\n",
    "\n",
    "data = get_train_pairs(data_bad, data_good, train_size=0.9, shuffle=True)\n",
    "\n",
    "history = trainer(model, data, weights_path, batch_size=batch_size, epochs=epochs)\n",
    "histories.append(history)\n",
    "acc = calc_acc(model, weights_path, data[1], data[3])  #from final_utils.py\n",
    "\n",
    "\n",
    "save_history(history, f'histories/{batch_size}_{epochs}')\n",
    "print('-----Accuracy =', acc, ' -----')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3237edea",
   "metadata": {},
   "source": [
    "## Version using tf.keras.preprocessing.image_dataset_from_directory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455226ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size= 8\n",
    "# img_height = 100\n",
    "# img_width = 100\n",
    "\n",
    "\n",
    "# ds_train = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "#     folder_path,\n",
    "#     labels=\"inferred\",\n",
    "#     label_mode=\"int\",  # categorical, binary\n",
    "#     # class_names=['0', '1', '2', '3', ...]\n",
    "#     color_mode=\"rgb\",\n",
    "#     batch_size=batch_size,\n",
    "#     image_size=(img_height, img_width),  # reshape if not in this size\n",
    "#     shuffle=True,\n",
    "#     seed=123,\n",
    "#     validation_split=0.1,\n",
    "#     subset=\"training\",\n",
    "# )\n",
    "\n",
    "# ds_validation = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "#     folder_path,\n",
    "#     labels=\"inferred\",\n",
    "#     label_mode=\"int\",  # categorical, binary\n",
    "#     # class_names=['0', '1', '2', '3', ...]\n",
    "#     color_mode=\"rgb\",\n",
    "#     batch_size=batch_size,\n",
    "#     image_size=(img_height, img_width),  # reshape if not in this size\n",
    "#     shuffle=True,\n",
    "#     seed=123,\n",
    "#     validation_split=0.1,\n",
    "#     subset=\"validation\",\n",
    "# )\n",
    "\n",
    "# model = model_inceptionresnet_multigap()\n",
    "\n",
    "# model.compile(\n",
    "#     optimizer=keras.optimizers.Adam(),\n",
    "#     loss=[keras.losses.SparseCategoricalCrossentropy(from_logits=True),],\n",
    "#     metrics=[\"accuracy\"],\n",
    "# )\n",
    "# model.fit(ds_train, epochs=10, verbose=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
