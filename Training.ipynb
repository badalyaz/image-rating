{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06da3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here you can \n",
    "# 1. Extract Features and save\n",
    "# 2. Transform features\n",
    "# 3. Load transformed features for training\n",
    "# 4. Train \n",
    "# 5. Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f7df97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from final_utils import *\n",
    "\n",
    "# generate root path\n",
    "root_path = generate_root_path() # else uncomment this"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "651f01c3",
   "metadata": {},
   "source": [
    "###  Feature extraction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "10357d89",
   "metadata": {},
   "source": [
    "#### Multigap feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8776727f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating model\n",
    "model_mg = model_inceptionresnet_multigap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817c9cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting train good image multigap features and saving with .json\n",
    "source_file = root_path + 'Data/splitted/train/images/good/good1'\n",
    "target_file = root_path + 'Data/splitted/train/features/mg/original/'\n",
    "\n",
    "extract_features_from_path_automated_json(\n",
    "                                     source_file=source_file,\n",
    "                                     target_file=target_file,\n",
    "                                     label='good',\n",
    "                                     splitted='good1',\n",
    "                                     model=model_mg,\n",
    "                                     resize_func=False,\n",
    "                                     save_json=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f959a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting train bad image multigap features and saving with .json\n",
    "target_file = root_path + 'Data/splitted/train/features/mg/original/'\n",
    "\n",
    "for i in range(7):\n",
    "    paths = root_path + f'Data/splitted/train/images/bad/bad{i+1}'\n",
    "    extract_features_from_path_automated_json(\n",
    "                                     source_file=paths,\n",
    "                                     target_file=target_file,\n",
    "                                     label='bad', \n",
    "                                     splitted=f'bad{i+1}',\n",
    "                                     model=model_mg,\n",
    "                                     resize_func=False,\n",
    "                                     save_json=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "114b582d",
   "metadata": {},
   "source": [
    "#### CNN feature ctraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7385e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating model\n",
    "model_cnn = tf.keras.Sequential([hub.KerasLayer(\"https://tfhub.dev/tensorflow/efficientnet/b7/feature-vector/1\",trainable=False) ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47f8b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting train good image cnn features and saving\n",
    "source_file = root_path + 'Data/splitted/train/images/good/good1'\n",
    "target_file = root_path + 'Data/splitted/train/features/cnn_efficientnet_b7/border_600x600/'\n",
    "\n",
    "extract_features_from_path_automated_json(\n",
    "                                     source_file=source_file,\n",
    "                                     target_file=target_file,\n",
    "                                     label='good',\n",
    "                                     splitted='good1',\n",
    "                                     model=model_cnn, \n",
    "                                     resize_func=resize_add_border,\n",
    "                                     size=(600, 600),\n",
    "                                     save_json=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57024275",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting train bad image cnn features and saving\n",
    "target_file = root_path + 'Data/splitted/train/features/cnn_efficientnet_b7/border_600x600/'\n",
    "\n",
    "for i in range(7):\n",
    "    paths = root_path + f'Data/splitted/train/images/bad/bad{i+1}'\n",
    "    extract_features_from_path_automated_json(\n",
    "                                     source_file=paths,\n",
    "                                     target_file=target_file,\n",
    "                                     label='bad', \n",
    "                                     splitted=f'bad{i+1}',\n",
    "                                     model=model_cnn, \n",
    "                                     resize_func=resize_add_border,\n",
    "                                     size=(600, 600),\n",
    "                                     save_json=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bba29ec8",
   "metadata": {},
   "source": [
    "### Dimentionality reduction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "684d626d",
   "metadata": {},
   "source": [
    "#### For multigap features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48560c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading feature vectors from paths\n",
    "paths = glob(f'{root_path}Data/splitted/train/features/mg/original/*')\n",
    "feator_vectors = []\n",
    "for path in paths:\n",
    "    feator_vectors.append(np.load(path))\n",
    "feator_vectors = np.asarray(feator_vectors)\n",
    "feator_vectors = np.squeeze(feator_vectors,axis = 1)\n",
    "print(feator_vectors.shape)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5833ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating model PCA and training\n",
    "pca_mg = PCA(n_components = 8464 , svd_solver = \"auto\")\n",
    "pca_mg.fit(feator_vectors)#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668a77ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# making directores for saving transformed features and pca model\n",
    "transformed_feats_path = f'{root_path}Data/splitted/train/features/mg/original_PCA_8464_auto'\n",
    "pca_mg_path = 'models/PCA'\n",
    "\n",
    "if not os.path.exists(transformed_feats_path):\n",
    "    os.mkdir(transformed_feats_path)\n",
    "if not os.path.exists(pca_mg_path):\n",
    "    os.mkdir(pca_mg_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c24b754",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving pca model\n",
    "pk.dump(pca_mg, open(f'{pca_mg_path}/PCA_MG_8464_auto.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdcba33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving transformed features\n",
    "for path in paths:\n",
    "    basename = (os.path.basename(path).split('.'))[0]\n",
    "    feat = np.load(path)\n",
    "    feat = pca_mg.transform(feat)\n",
    "    np.save(os.path.join(transformed_feats_path, basename), feat)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "642d0bfb",
   "metadata": {},
   "source": [
    "#### For cnn features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e957dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading feature vectors from paths\n",
    "paths = glob(f'{root_path}Data/splitted/train/features/cnn_efficientnet_b7/border_600x600/*')\n",
    "feator_vectors = []\n",
    "for path in paths:\n",
    "    feator_vectors.append(np.load(path))\n",
    "feator_vectors = np.asarray(feator_vectors)\n",
    "feator_vectors = np.squeeze(feator_vectors,axis = 1)\n",
    "print(feator_vectors.shape)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05de77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating model PCA and training\n",
    "pca_cnn = PCA(n_components = 1280 , svd_solver = \"auto\")\n",
    "pca_cnn.fit(feator_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39141c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# making directores for saving transformed features and pca model\n",
    "transformed_feats_path = f'{root_path}Data/splitted/train/features/cnn_efficientnet_b7/border_600x600_PCA_1280_auto'\n",
    "pca_cnn_path = 'models/PCA'\n",
    "if not os.path.exists(transformed_feats_path):\n",
    "    os.mkdir(transformed_feats_path)\n",
    "if not os.path.exists(pca_cnn_path):\n",
    "    os.mkdir(pca_cnn_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4c8e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving pca model\n",
    "pk.dump(pca_cnn, open(f'{pca_cnn_path}/PCA_CNN_1280_auto.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37693179",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving transformed features\n",
    "for path in paths:\n",
    "    basename = (os.path.basename(path).split('.'))[0]\n",
    "    feat = np.load(path)\n",
    "    feat = pca_cnn.transform(feat)\n",
    "    np.save(os.path.join(transformed_feats_path, basename), feat)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4d98f1ed",
   "metadata": {},
   "source": [
    "### Training FC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3606c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define loss function\n",
    "SC_CE_KLD = tf.keras.losses.SparseCategoricalCrossentropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998e658d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading cnn features and multigap features from .json\n",
    "main_path = root_path + 'Data/splitted/train/'\n",
    "features_bad_list = []\n",
    "features_bad_list_i = []\n",
    "features_good1 = []\n",
    "feats_MG = 'original_PCA_8464_auto' \n",
    "feats_CNN = 'border_600x600_PCA_1280_auto'\n",
    "    \n",
    "for i in range(7):\n",
    "    alm_train_bad = open(f'{main_path}data_bad{i+1}.json')\n",
    "    bad_data = json.load(alm_train_bad)\n",
    "    for data in bad_data:\n",
    "        feat_path_1 = main_path + f'features/MG/{feats_MG}/' + data['feature']\n",
    "        feat_path_2 = main_path + f'features/cnn_efficientnet_b7/{feats_CNN}/' + data['feature']\n",
    "        connected = np.concatenate((np.squeeze(np.load(feat_path_1)), np.squeeze(np.load(feat_path_2))))\n",
    "        features_bad_list_i.append(connected)\n",
    "    features_bad_list.append(features_bad_list_i)\n",
    "    features_bad_list_i = []\n",
    "        \n",
    "alm_train_good = open(f'{main_path}/data_good1.json')\n",
    "good_data = json.load(alm_train_good)\n",
    "for data in good_data:\n",
    "    feat_path_1 = main_path + f'features/mg/{feats_MG}/' + data['feature']\n",
    "    feat_path_2 = main_path + f'features/cnn_efficientnet_b7/{feats_CNN}/' + data['feature']\n",
    "    connected = np.concatenate((np.squeeze(np.load(feat_path_1)), np.squeeze(np.load((feat_path_2)))))\n",
    "    features_good1.append(connected)\n",
    "    \n",
    "for i in range(7):\n",
    "    features_bad_list[i] = np.squeeze(np.array(features_bad_list[i]))\n",
    "features_good1 = np.squeeze(np.array(features_good1))\n",
    "   \n",
    "# Generating static validation data\n",
    "features_bad_list[0], features_bad1_val = extract_static_val_data(features_bad_list[0], perc = 0.11)\n",
    "features_good1, features_good1_val = extract_static_val_data(features_good1, perc = 0.11)\n",
    "\n",
    "bad = features_bad_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac0b337",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating validation data\n",
    "X_val = np.concatenate((features_bad1_val, features_good1_val) , axis=0 )\n",
    "y_val = np.concatenate((np.zeros(len(features_bad1_val)), np.ones(len(features_good1_val))), axis=0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f7afb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer\n",
    "def trainer(model, data, weights_path, data_val,batch_size=128, epochs=30, learning_rate=0.03):\n",
    "    X_train, X_test, y_train, y_test = data\n",
    "\n",
    "    model.compile(loss=SC_CE_KLD,\n",
    "                  optimizer=keras.optimizers.Adam(learning_rate=learning_rate, beta_1=0.9, beta_2=0.999, \n",
    "                                                  epsilon=1e-07, decay=0, amsgrad=False))\n",
    "    model.load_weights(weights_path) \n",
    "    checkpoint = keras.callbacks.ModelCheckpoint(weights_path, \n",
    "                                                 monitor='val_loss', \n",
    "                                                 verbose=1, \n",
    "                                                 save_best_only=True, \n",
    "                                                 mode='min')\n",
    "    schedule = tf.keras.callbacks.LearningRateScheduler(lr_exp_decay, verbose=0)\n",
    "    callbacks_list = [checkpoint, schedule]\n",
    "\n",
    "    history = model.fit(X_train, y_train,\n",
    "                        batch_size=batch_size,\n",
    "                        epochs=epochs,\n",
    "                        verbose=1,\n",
    "                        callbacks=callbacks_list,\n",
    "                        validation_data = data_val)\n",
    "\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd60b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating fc model and weights\n",
    "model_fc = fc_model_softmax(input_num=9744)\n",
    "weights_path = f'models/model_fc_softmax.hdf5' #path where will save model weights\n",
    "model_fc.save_weights(weights_path) #if we want to cancel learning and start from 0, if not comment the line\n",
    "model_fc.load_weights(weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0440b368",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining epochs count, batch size and learning rate\n",
    "epochs = 15\n",
    "batch_size = 128\n",
    "learning_rate = 0.003"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "15d70df5",
   "metadata": {},
   "source": [
    "### Attention !!! in block below the counter \"i\" must be changed manualy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa25200",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_val = (X_val, y_val)\n",
    "\n",
    "i =  # Set i the nesseccary one, as we take a pair of one good and one bad (from 7)\n",
    "data = get_train_pairs(bad[i], features_good1, train_size=0.95, shuffle=True)\n",
    "if True:\n",
    "    history = trainer(model_fc, data, weights_path, data_val, batch_size, epochs, learning_rate=learning_rate)\n",
    "    acc = calc_acc(model_fc, weights_path, data_val[0], data_val[1], batch_size)\n",
    "    print('----- Accuracy =', acc, '%', ' -----')\n",
    "    print('---Batch Train Done---')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "28f8ca3e",
   "metadata": {},
   "source": [
    "### Evaluation on benchmark_1 and benchmark_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15dc1168",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading fc weights\n",
    "model_fc.load_weights(weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec29ec2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading pca models, if need\n",
    "pca_mg = pk.load(open(f'{pca_mg_path}/PCA_MG_8464_auto.pkl', 'rb'))\n",
    "pca_cnn = pk.load(open(f'{pca_cnn_path}/PCA_CNN_1280_auto.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1029d81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading paths of benchmark datas\n",
    "good_imgs_path = glob(os.path.join(root_path, 'Data', 'benchmark', 'images', 'good', '*'))\n",
    "bad_imgs_path = glob(os.path.join(root_path, 'Data', 'benchmark', 'images', 'bad', '*'))\n",
    "\n",
    "good_imgs_path_2 = glob(os.path.join(root_path, 'Data', 'benchmark2', 'images', 'good', '*'))\n",
    "bad_imgs_path_2 = glob(os.path.join(root_path, 'Data', 'benchmark2', 'images', 'bad', '*'))\n",
    "\n",
    "# Creating labels of loaded benchmark data paths\n",
    "paths_bench = good_imgs_path + bad_imgs_path\n",
    "labels_bench = np.concatenate((np.ones(len(good_imgs_path)), np.zeros(len(bad_imgs_path))))\n",
    "\n",
    "paths_bench_2 = good_imgs_path_2 + bad_imgs_path_2\n",
    "labels_bench_2 = np.concatenate((np.ones(len(good_imgs_path_2)), np.zeros(len(bad_imgs_path_2))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3bd56a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some necessary functions for prediction\n",
    "def predict(x, y=None, model_gap=None, model=None, model_cnn=None, is_norm=False, pca_mg=None, pca_cnn = None):\n",
    "    '''\n",
    "    Does prediction on given numpy image using\n",
    "    model_gap and model\n",
    "    '''\n",
    "    try:\n",
    "        feat_mg = model_gap.predict(x, verbose=0)\n",
    "    except:\n",
    "        x = x[None] #changed 02.08 for evaluator visualizing predictions\n",
    "        feat_mg = model_gap.predict(x, verbose=0)\n",
    "        \n",
    "    if pca_mg:\n",
    "        feat_mg = pca_mg.transform(feat_mg)\n",
    "    if model_cnn:\n",
    "        feat_cnn = model_cnn.predict(y, verbose=0)\n",
    "        if is_norm:\n",
    "            feat_cnn = normalize_feat_vector(feat_cnn)\n",
    "        if pca_cnn:\n",
    "            feat_cnn = pca_cnn.transform(feat_cnn)\n",
    "        feat = np.concatenate((np.squeeze(feat_mg), np.squeeze(feat_cnn)))\n",
    "        feat = feat[None]\n",
    "    else:\n",
    "        feat = feat_mg\n",
    "    pred_score = model.predict(feat, verbose=0)\n",
    "\n",
    "    return pred_score\n",
    "    \n",
    "def predict_from_path(model_gap, model, paths, resize_func=None, size=None, for_all=False, save_results=None, \n",
    "                      save_to=None, model_cnn=None, is_norm=False, pca_mg = None, pca_cnn = None):\n",
    "    #always requires list of paths\n",
    "    predicted = []\n",
    "    \n",
    "    for i, path in enumerate(paths):\n",
    "        img_mg = read_img(path=path, resize_func=resize_func, size=size, for_all=True)\n",
    "        img_cnn = None\n",
    "        if model_cnn:\n",
    "            img_cnn = read_img(path=path, resize_func=resize_add_border, size=(600, 600))\n",
    "        pred_score = predict(img_mg, img_cnn, model_gap, model, model_cnn, is_norm, pca_mg, pca_cnn)\n",
    "        predicted.append(pred_score)\n",
    "    \n",
    "    predicted = np.array(predicted)\n",
    "    predicted = np.squeeze(predicted)\n",
    "    \n",
    "    if save_results:\n",
    "        np.save(save_to, np.argmax(predicted, axis=-1))\n",
    "        \n",
    "    return predicted\n",
    "\n",
    "def plot_pred_orig(model_gap, model, imgs_bench, label=None, row_count=2, column_count=10, resize_func=None, size=None, for_all=False, model_cnn=None, is_norm=False, pca_mg=None, pca_cnn=None):\n",
    "    f, axarr = plt.subplots(row_count, column_count,  figsize=(20,5))\n",
    "\n",
    "    for i, path in enumerate(imgs_bench):\n",
    "        x = i // column_count\n",
    "        y = i % column_count\n",
    "\n",
    "        img_mg = read_img(path, resize_func=resize_func, size=size, for_all=for_all)\n",
    "        \n",
    "        img_cnn = None\n",
    "        if model_cnn:\n",
    "            img_cnn = read_img(path=path, resize_func=resize_add_border, size=(600, 600))\n",
    "            \n",
    "        pred_score = predict(img_mg, img_cnn, model_gap, model, model_cnn, is_norm, pca_mg, pca_cnn)\n",
    "\n",
    "        im = cv2.imread(path)\n",
    "        im = cv2.resize(im, (400, 400))\n",
    "        \n",
    "        if row_count == 1:\n",
    "            axarr[i].imshow(im[..., ::-1]) \n",
    "            axarr[i].set_title(f'{str(np.argmax(pred_score, axis=-1)[0])}\\n{str(np.round(np.max(pred_score, axis=-1),3)[0])}', fontsize=12)\n",
    "        else:\n",
    "            axarr[x, y].imshow(im[..., ::-1]) \n",
    "            axarr[x, y].set_title(f'{str(np.argmax(pred_score, axis=-1)[0])}\\n{str(np.round(np.max(pred_score, axis=-1),3)[0])}', fontsize=12)\n",
    "\n",
    "    if label:\n",
    "        f.suptitle('test on ' + label, fontsize=17)\n",
    "    else: \n",
    "        f.suptitle('Predictions', fontsize=17)\n",
    "    plt.setp(plt.gcf().get_axes(), xticks=[], yticks=[])\n",
    "    plt.show()\n",
    "\n",
    "def calc_acc(labels, predicted):\n",
    "    '''\n",
    "    Calculating mean class error, e.g. predicted classes are 1vs0, 0vs0, 0vs0, 0vs0, then we have acc=0.25\n",
    "    Inputs: \n",
    "        labels = target labels\n",
    "        predicted = predicted binary probability distribution for the input\n",
    "    Output:\n",
    "        mean class error\n",
    "    '''\n",
    "    acc = np.sum(np.array(labels) == np.argmax(np.array(predicted), axis=1)) / len(labels)\n",
    "    return np.round(acc * 100, 2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "765cc85b",
   "metadata": {},
   "source": [
    "#### Prediction on benchmark_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46925702",
   "metadata": {},
   "outputs": [],
   "source": [
    "#resize_max (996, 996) means if images' height or width > 996 then resize with maximum 996 and another with aspect ratio\n",
    "predicted = predict_from_path(model_mg, model_fc, paths_bench, resize_func=resize_max, size=(996, 996), for_all=False,\n",
    "                              model_cnn=model_cnn, is_norm=False, pca_mg=pca_mg, pca_cnn=pca_cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1118ea1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calc accuracy\n",
    "acc = calc_acc(labels_bench, predicted)\n",
    "print(f'Accuracy: {acc} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ecc6e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precision and Recall\n",
    "pred = np.argmax(predicted, axis=1)\n",
    "calc_metrics(labels_bench, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00dfbd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing \n",
    "data_size = 20\n",
    "plot_pred_orig(model_mg, model_fc, good_imgs_path[:data_size], resize_func=resize_max, \n",
    "               label='Good', size=(996, 996), model_cnn=model_cnn, pca_mg=pca_mg, pca_cnn=pca_cnn)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d88d8737",
   "metadata": {},
   "source": [
    "#### Prediction on benchmark_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d44563",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = predict_from_path(model_mg, model_fc, paths_bench_2, resize_func=resize_max, size=(996, 996), for_all=False,\n",
    "                              model_cnn=model_cnn, is_norm=False, pca_mg=pca_mg, pca_cnn=pca_cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85770da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calc accuracy\n",
    "acc = calc_acc(labels_bench_2, predicted)\n",
    "print(f'Accuracy: {acc} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd0fa6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precision and Recall\n",
    "pred = np.argmax(predicted, axis=1)\n",
    "calc_metrics(labels_bench_2, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4aba43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing \n",
    "data_size = 20\n",
    "plot_pred_orig(model_mg, model_fc, good_imgs_path_2[:data_size], resize_func=resize_max, \n",
    "               label='Good', size=(996, 996), for_all=True, model_cnn=model_cnn, pca_mg=pca_mg, pca_cnn=pca_cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcfbf214",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
