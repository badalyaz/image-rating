{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6ff9f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage\n",
    "import matplotlib.image as img\n",
    "from glob import glob\n",
    "from final_utils import *\n",
    "from MultiGap_FC import *\n",
    "from lime import lime_image\n",
    "from MultiGap_CNN_FC import *\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from skimage.segmentation import mark_boundaries"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d1bd929b",
   "metadata": {},
   "source": [
    "### Creating model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51eb6e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = model_multigap_cnn_fc( pca_mg = True, pca_cnn = True)\n",
    "# model2 = model_multigap_fc()\n",
    "root_path = generate_root_path()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24ee7a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "good_imgs_path = glob(os.path.join(root_path, 'Data', 'benchmark', 'images', 'good', '*'))\n",
    "bad_imgs_path = glob(os.path.join(root_path, 'Data', 'benchmark', 'images', 'bad', '*'))\n",
    "paths_bench = good_imgs_path + bad_imgs_path\n",
    "labels_bench = np.concatenate((np.ones(len(good_imgs_path)) ,np.zeros(len(bad_imgs_path))))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "02a6501c",
   "metadata": {},
   "source": [
    "### Some useful functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a71e6ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_acc(labels, predicted):\n",
    "    return np.sum(np.array(labels) == np.argmax(np.array(predicted), axis=1)) / len(labels)\n",
    "\n",
    "def predict(x, model):\n",
    "    try:\n",
    "        pred = model.predict(x, verbose=0)\n",
    "    except:\n",
    "        x = x[None] #changed 02.08 for evaluator visualizing predictions\n",
    "        pred = model.predict(x, verbose=0)\n",
    "\n",
    "    return pred\n",
    "\n",
    "def predict_from_path(model, paths, resize_func=None, size=None, for_all=False, save_results=None, save_to=None, model_CNN=None):\n",
    "    #always requires list of paths\n",
    "    predicted = []\n",
    "    false_pred = []\n",
    "    \n",
    "    for path in paths:\n",
    "        if 'good' in path:\n",
    "            label = 1\n",
    "        elif 'bad' in path:\n",
    "            label = 0\n",
    "\n",
    "        img = read_img(path=path, resize_func=resize_func, size=size, for_all=for_all)\n",
    "        pred_score = predict(img, model)\n",
    "    \n",
    "        if np.argmax(pred_score) != label:\n",
    "            false_pred.append(path)\n",
    "            \n",
    "        predicted.append(pred_score)\n",
    "    \n",
    "    predicted = np.array(predicted)\n",
    "    predicted = np.squeeze(predicted)\n",
    "    \n",
    "#     if save_results:\n",
    "#         np.save(save_to, np.argmax(predicted, axis=-1))\n",
    "        \n",
    "    return predicted, false_pred\n",
    "\n",
    "def read_and_transform_img(url):\n",
    "    img = Image.open(url)\n",
    "    img = img_to_array(img)\n",
    "#     img = img / 255\n",
    "#     img = resize_max(img, size=(996,996))\n",
    "    print(img.shape)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "\n",
    "    return img"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7f721881",
   "metadata": {},
   "source": [
    "### Saparating false predicted images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4787bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predicted, false_pred = predict_from_path(model1, paths_bench, resize_func=resize_max, size=(996, 996))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4253b2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = calc_acc(labels_bench, predicted)\n",
    "print(f'Accuracy: {acc}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "08e84f4a",
   "metadata": {},
   "source": [
    "### Explanation for false predictions with LIME "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c6864cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = lime_image.LimeImageExplainer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ebd6a925",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1079, 894, 3)\n",
      "<class 'numpy.ndarray'>\n",
      "image shape (None, 1079, 894, 3)\n",
      "Resize max (1079, 894, 3)\n",
      "image shape after resize max (1, 996, 825, 3)\n",
      "mg feature vector shape (1, 16928)\n",
      "image shape after resize border (1, 600, 600, 3)\n",
      "cnn feature vector shape (None, 2560)\n",
      "mg feature vector shape after pca (1, 8464)\n",
      "cnn feature vector shape after pca (None, 1280)\n",
      "feature vector shape after concat (1, 9744)\n",
      "feature vector shape after fc (1, 2)\n",
      "print before return\n",
      "1/1 [==============================] - 26s 26s/step\n",
      "It's no aesthethic!\n",
      "[[9.9987686e-01 1.2312659e-04]]\n"
     ]
    }
   ],
   "source": [
    "path = \"XAI/gal-angebot-portrait-1.jpg\"\n",
    "\n",
    "images = read_and_transform_img(path)\n",
    "print(type(images))\n",
    "preds = model1.predict(images)\n",
    "prediction = np.argmax(preds)\n",
    "pct = np.max(preds)\n",
    "if prediction == 0:\n",
    "    print('It\\'s no aesthethic!')\n",
    "elif prediction == 1:\n",
    "    print('It\\'s an aesthethic!')\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27217d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0 # index of false predicted image which will be explained\n",
    "\n",
    "images = read_and_transform_img(false_pred[i])\n",
    "basename = os.path.basename(false_pred[i])\n",
    "preds = model1.predict(images)\n",
    "prediction = np.argmax(preds)\n",
    "pct = np.max(preds)\n",
    "\n",
    "if prediction == 0:\n",
    "    print('It\\'s no aesthethic!')\n",
    "elif prediction == 1:\n",
    "    print('It\\'s an aesthethic!')\n",
    "\n",
    "print(pct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "07b39445",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca20c1a10d1c4155b47a5b1275b5300a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 570ms/step\n",
      "1/1 [==============================] - 0s 445ms/step\n",
      "1/1 [==============================] - 0s 460ms/step\n",
      "1/1 [==============================] - 0s 476ms/step\n",
      "1/1 [==============================] - 0s 450ms/step\n",
      "1/1 [==============================] - 0s 490ms/step\n",
      "1/1 [==============================] - 0s 488ms/step\n",
      "1/1 [==============================] - 1s 523ms/step\n",
      "1/1 [==============================] - 0s 494ms/step\n",
      "1/1 [==============================] - 0s 452ms/step\n",
      "1/1 [==============================] - 0s 456ms/step\n",
      "1/1 [==============================] - 0s 493ms/step\n",
      "1/1 [==============================] - 0s 470ms/step\n",
      "1/1 [==============================] - 0s 491ms/step\n",
      "1/1 [==============================] - 0s 409ms/step\n",
      "1/1 [==============================] - 0s 450ms/step\n",
      "1/1 [==============================] - 0s 479ms/step\n",
      "1/1 [==============================] - 0s 443ms/step\n",
      "1/1 [==============================] - 0s 485ms/step\n",
      "1/1 [==============================] - 0s 498ms/step\n",
      "1/1 [==============================] - 1s 500ms/step\n",
      "1/1 [==============================] - 0s 476ms/step\n",
      "1/1 [==============================] - 0s 383ms/step\n",
      "1/1 [==============================] - 0s 465ms/step\n",
      "1/1 [==============================] - 0s 468ms/step\n",
      "1/1 [==============================] - 0s 464ms/step\n",
      "1/1 [==============================] - 1s 519ms/step\n",
      "1/1 [==============================] - 1s 522ms/step\n",
      "1/1 [==============================] - 1s 517ms/step\n",
      "1/1 [==============================] - 0s 489ms/step\n",
      "1/1 [==============================] - 0s 479ms/step\n",
      "1/1 [==============================] - 0s 447ms/step\n",
      "1/1 [==============================] - 0s 486ms/step\n",
      "1/1 [==============================] - 0s 484ms/step\n",
      "1/1 [==============================] - 1s 504ms/step\n",
      "1/1 [==============================] - 0s 494ms/step\n",
      "1/1 [==============================] - 1s 518ms/step\n",
      "1/1 [==============================] - 1s 522ms/step\n",
      "1/1 [==============================] - 0s 472ms/step\n",
      "1/1 [==============================] - 0s 456ms/step\n",
      "1/1 [==============================] - 0s 457ms/step\n",
      "1/1 [==============================] - 0s 479ms/step\n",
      "1/1 [==============================] - 0s 477ms/step\n",
      "1/1 [==============================] - 0s 433ms/step\n",
      "1/1 [==============================] - 0s 451ms/step\n",
      "1/1 [==============================] - 0s 451ms/step\n",
      "1/1 [==============================] - 0s 470ms/step\n",
      "1/1 [==============================] - 0s 451ms/step\n",
      "1/1 [==============================] - 0s 460ms/step\n",
      "1/1 [==============================] - 0s 396ms/step\n",
      "1/1 [==============================] - 0s 438ms/step\n",
      "1/1 [==============================] - 0s 422ms/step\n",
      "1/1 [==============================] - 0s 479ms/step\n",
      "1/1 [==============================] - 0s 475ms/step\n",
      "1/1 [==============================] - 0s 447ms/step\n",
      "1/1 [==============================] - 0s 468ms/step\n",
      "1/1 [==============================] - 0s 486ms/step\n",
      "1/1 [==============================] - 0s 477ms/step\n",
      "1/1 [==============================] - 0s 455ms/step\n",
      "1/1 [==============================] - 1s 500ms/step\n",
      "1/1 [==============================] - 0s 482ms/step\n",
      "1/1 [==============================] - 0s 430ms/step\n",
      "1/1 [==============================] - 0s 467ms/step\n",
      "1/1 [==============================] - 0s 441ms/step\n",
      "1/1 [==============================] - 0s 472ms/step\n",
      "1/1 [==============================] - 0s 454ms/step\n",
      "1/1 [==============================] - 0s 456ms/step\n",
      "1/1 [==============================] - 0s 476ms/step\n",
      "1/1 [==============================] - 1s 501ms/step\n",
      "1/1 [==============================] - 0s 454ms/step\n",
      "1/1 [==============================] - 0s 455ms/step\n",
      "1/1 [==============================] - 0s 457ms/step\n",
      "1/1 [==============================] - 0s 450ms/step\n",
      "1/1 [==============================] - 0s 464ms/step\n",
      "1/1 [==============================] - 0s 462ms/step\n",
      "1/1 [==============================] - 0s 491ms/step\n",
      "1/1 [==============================] - 0s 476ms/step\n",
      "1/1 [==============================] - 0s 462ms/step\n",
      "1/1 [==============================] - 0s 452ms/step\n",
      "1/1 [==============================] - 0s 494ms/step\n",
      "1/1 [==============================] - 0s 445ms/step\n",
      "1/1 [==============================] - 0s 497ms/step\n",
      "1/1 [==============================] - 0s 482ms/step\n",
      "1/1 [==============================] - 0s 454ms/step\n",
      "1/1 [==============================] - 0s 428ms/step\n",
      "1/1 [==============================] - 0s 431ms/step\n",
      "1/1 [==============================] - 0s 419ms/step\n",
      "1/1 [==============================] - 0s 491ms/step\n",
      "1/1 [==============================] - 1s 509ms/step\n",
      "1/1 [==============================] - 0s 481ms/step\n",
      "1/1 [==============================] - 0s 437ms/step\n",
      "1/1 [==============================] - 0s 486ms/step\n",
      "1/1 [==============================] - 0s 498ms/step\n",
      "1/1 [==============================] - 0s 447ms/step\n",
      "1/1 [==============================] - 0s 463ms/step\n",
      "1/1 [==============================] - 0s 478ms/step\n",
      "1/1 [==============================] - 0s 448ms/step\n",
      "1/1 [==============================] - 0s 459ms/step\n",
      "1/1 [==============================] - 0s 481ms/step\n",
      "1/1 [==============================] - 0s 486ms/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [1000, 100]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m explanation \u001b[38;5;241m=\u001b[39m \u001b[43mexplainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexplain_instance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdouble\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m                                     \u001b[49m\u001b[43mtop_labels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhide_color\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m temp_1, mask_1 \u001b[38;5;241m=\u001b[39m explanation\u001b[38;5;241m.\u001b[39mget_image_and_mask(explanation\u001b[38;5;241m.\u001b[39mtop_labels[\u001b[38;5;241m0\u001b[39m], positive_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, num_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, hide_rest\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      5\u001b[0m temp_2, mask_2 \u001b[38;5;241m=\u001b[39m explanation\u001b[38;5;241m.\u001b[39mget_image_and_mask(explanation\u001b[38;5;241m.\u001b[39mtop_labels[\u001b[38;5;241m0\u001b[39m], positive_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, num_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, hide_rest\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\.conda\\envs\\tf\\lib\\site-packages\\lime\\lime_image.py:216\u001b[0m, in \u001b[0;36mLimeImageExplainer.explain_instance\u001b[1;34m(self, image, classifier_fn, labels, hide_color, top_labels, num_features, num_samples, batch_size, segmentation_fn, distance_metric, model_regressor, random_seed)\u001b[0m\n\u001b[0;32m    212\u001b[0m     ret_exp\u001b[38;5;241m.\u001b[39mtop_labels\u001b[38;5;241m.\u001b[39mreverse()\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m label \u001b[38;5;129;01min\u001b[39;00m top:\n\u001b[0;32m    214\u001b[0m     (ret_exp\u001b[38;5;241m.\u001b[39mintercept[label],\n\u001b[0;32m    215\u001b[0m      ret_exp\u001b[38;5;241m.\u001b[39mlocal_exp[label],\n\u001b[1;32m--> 216\u001b[0m      ret_exp\u001b[38;5;241m.\u001b[39mscore, ret_exp\u001b[38;5;241m.\u001b[39mlocal_pred) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexplain_instance_with_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    217\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdistances\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    218\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_regressor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_regressor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    219\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeature_selection\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeature_selection\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    220\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ret_exp\n",
      "File \u001b[1;32m~\\.conda\\envs\\tf\\lib\\site-packages\\lime\\lime_base.py:183\u001b[0m, in \u001b[0;36mLimeBase.explain_instance_with_data\u001b[1;34m(self, neighborhood_data, neighborhood_labels, distances, label, num_features, feature_selection, model_regressor)\u001b[0m\n\u001b[0;32m    181\u001b[0m weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel_fn(distances)\n\u001b[0;32m    182\u001b[0m labels_column \u001b[38;5;241m=\u001b[39m neighborhood_labels[:, label]\n\u001b[1;32m--> 183\u001b[0m used_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeature_selection\u001b[49m\u001b[43m(\u001b[49m\u001b[43mneighborhood_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    184\u001b[0m \u001b[43m                                       \u001b[49m\u001b[43mlabels_column\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    185\u001b[0m \u001b[43m                                       \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    186\u001b[0m \u001b[43m                                       \u001b[49m\u001b[43mnum_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    187\u001b[0m \u001b[43m                                       \u001b[49m\u001b[43mfeature_selection\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model_regressor \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    189\u001b[0m     model_regressor \u001b[38;5;241m=\u001b[39m Ridge(alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, fit_intercept\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    190\u001b[0m                             random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrandom_state)\n",
      "File \u001b[1;32m~\\.conda\\envs\\tf\\lib\\site-packages\\lime\\lime_base.py:134\u001b[0m, in \u001b[0;36mLimeBase.feature_selection\u001b[1;34m(self, data, labels, weights, num_features, method)\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    133\u001b[0m     n_method \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhighest_weights\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 134\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeature_selection\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    135\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mnum_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_method\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\tf\\lib\\site-packages\\lime\\lime_base.py:80\u001b[0m, in \u001b[0;36mLimeBase.feature_selection\u001b[1;34m(self, data, labels, weights, num_features, method)\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhighest_weights\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m     78\u001b[0m     clf \u001b[38;5;241m=\u001b[39m Ridge(alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m, fit_intercept\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     79\u001b[0m                 random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrandom_state)\n\u001b[1;32m---> 80\u001b[0m     \u001b[43mclf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweights\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     82\u001b[0m     coef \u001b[38;5;241m=\u001b[39m clf\u001b[38;5;241m.\u001b[39mcoef_\n\u001b[0;32m     83\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sp\u001b[38;5;241m.\u001b[39msparse\u001b[38;5;241m.\u001b[39missparse(data):\n",
      "File \u001b[1;32m~\\.conda\\envs\\tf\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:1122\u001b[0m, in \u001b[0;36mRidge.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1102\u001b[0m \u001b[38;5;124;03m\"\"\"Fit Ridge regression model.\u001b[39;00m\n\u001b[0;32m   1103\u001b[0m \n\u001b[0;32m   1104\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1119\u001b[0m \u001b[38;5;124;03m    Fitted estimator.\u001b[39;00m\n\u001b[0;32m   1120\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1121\u001b[0m _accept_sparse \u001b[38;5;241m=\u001b[39m _get_valid_accept_sparse(sparse\u001b[38;5;241m.\u001b[39missparse(X), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msolver)\n\u001b[1;32m-> 1122\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1123\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1124\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1125\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_accept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1126\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat64\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1127\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1128\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_numeric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1129\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mfit(X, y, sample_weight\u001b[38;5;241m=\u001b[39msample_weight)\n",
      "File \u001b[1;32m~\\.conda\\envs\\tf\\lib\\site-packages\\sklearn\\base.py:596\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    594\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[0;32m    595\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 596\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m check_X_y(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m    597\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    599\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[1;32m~\\.conda\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\validation.py:1092\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1074\u001b[0m X \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[0;32m   1075\u001b[0m     X,\n\u001b[0;32m   1076\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1087\u001b[0m     input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1088\u001b[0m )\n\u001b[0;32m   1090\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[1;32m-> 1092\u001b[0m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1094\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X, y\n",
      "File \u001b[1;32m~\\.conda\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\validation.py:387\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    385\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[0;32m    386\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 387\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    388\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    389\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[0;32m    390\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [1000, 100]"
     ]
    }
   ],
   "source": [
    "explanation = explainer.explain_instance(images[0].astype('double'), model1.predict,  \n",
    "                                     top_labels=2, hide_color=0, num_samples=1000)\n",
    "\n",
    "temp_1, mask_1 = explanation.get_image_and_mask(explanation.top_labels[0], positive_only=True, num_features=5, hide_rest=True)\n",
    "temp_2, mask_2 = explanation.get_image_and_mask(explanation.top_labels[0], positive_only=False, num_features=10, hide_rest=False)\n",
    "\n",
    "img1 = mark_boundaries(temp_1, mask_1)\n",
    "img2 = mark_boundaries(temp_2, mask_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f278550f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
