{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b9be8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "from final_utils import *\n",
    "from keras.layers import Concatenate\n",
    "from MultiGap_CNN_FC import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1015350c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_base = model_inceptionresnet_multigap()\n",
    "model_cnn = tf.keras.Sequential([hub.KerasLayer(\"https://tfhub.dev/tensorflow/efficientnet/b7/feature-vector/1\",trainable=False) ])   \n",
    "model_fc = fc_model_softmax(input_num=9744)\n",
    "model_fc.load_weights(\"models/Softmax/MG_CNN/model_fc_softmax_MG_8k_B7_1k_600x600.hdf5\")#model_fc_softmax_MG_8k_B7_1k_600x600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9df53bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_mg_path = 'models/PCA/PCA_MG_8464_auto.pkl'\n",
    "pca_cnn_path= 'models/PCA/PCA_CNN_1280_auto.pkl'\n",
    "pca_mg = pk.load(open(pca_mg_path,'rb'))\n",
    "pca_cnn = pk.load(open(pca_cnn_path,'rb'))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "adda17d3",
   "metadata": {},
   "source": [
    "## Creating model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6cceb05",
   "metadata": {},
   "outputs": [],
   "source": [
    "model =  model_multigap_cnn_fc( pca_mg = True, pca_cnn = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7207432a",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = generate_root_path()\n",
    "good_imgs_path = glob(os.path.join(root_path, 'Data', 'benchmark', 'images', 'good', '*'))\n",
    "bad_imgs_path = glob(os.path.join(root_path, 'Data', 'benchmark', 'images', 'bad', '*'))\n",
    "paths_bench = good_imgs_path + bad_imgs_path\n",
    "labels_bench = np.concatenate((np.ones(len(good_imgs_path)) ,np.zeros(len(bad_imgs_path))))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8e1c252c",
   "metadata": {},
   "source": [
    "## Some useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ecc83b55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(875, 1200, 3)\n"
     ]
    }
   ],
   "source": [
    "def calc_acc(labels, predicted):\n",
    "    return np.sum(np.array(labels) == np.argmax(np.array(predicted), axis=1)) / len(labels)\n",
    "\n",
    "def predicts(x, model):\n",
    "    try:\n",
    "        pred = model.predict(x, verbose=0)\n",
    "    except:\n",
    "        x = x[None] #changed 02.08 for evaluator visualizing predictions\n",
    "        pred = model.predict(x, verbose=0)\n",
    "   \n",
    "    return pred\n",
    "\n",
    "img = read_img(path=paths_bench[0], resize_func=None, size=None, for_all=False)\n",
    "img = np.squeeze(img, axis=0)\n",
    "print(img.shape)\n",
    "\n",
    "def predict_from_path_false_pred(model, paths, model_CNN=None, resize_func=None, size=None, for_all=False, save_results=None, save_to=None, \n",
    "                     is_norm=True):\n",
    "    #always requires list of paths\n",
    "    predicted = []\n",
    "    false_pred = []\n",
    "    \n",
    "    for path in paths:\n",
    "        \n",
    "        if 'good' in path:\n",
    "            label = 1\n",
    "        elif 'bad' in path:\n",
    "            label = 0\n",
    "\n",
    "        img = read_img(path=path, resize_func=resize_func, size=size, for_all=for_all)\n",
    "        img = np.squeeze(img, axis=0)\n",
    "        print(img.shape)\n",
    "        \n",
    "        print(model)\n",
    "        pred_score = predicts(img, model)\n",
    "    \n",
    "        if np.argmax(pred_score) != label:\n",
    "            false_pred.append(path)\n",
    "            \n",
    "        predicted.append(pred_score)\n",
    "    \n",
    "    predicted = np.array(predicted)\n",
    "    predicted = np.squeeze(predicted)\n",
    "    \n",
    "    if save_results:\n",
    "        np.save(save_to, np.argmax(predicted, axis=-1))\n",
    "        \n",
    "    return predicted, false_pred\n",
    "\n",
    "# def predict_from_path(model_gap, model, paths, resize_func=None, size=None, for_all=False, save_results=None,\n",
    "#                       save_to=None, model_CNN=None, is_norm=False):\n",
    "#     #always requires list of paths\n",
    "#     predicted = []\n",
    "#     false_pred = []\n",
    "    \n",
    "#     for path in paths:\n",
    "#         if 'good' in path:\n",
    "#             label = 1\n",
    "#         elif 'bad' in path:\n",
    "#             label = 0\n",
    "    \n",
    "# #     for i, path in enumerate(paths):\n",
    "#         img_mg = read_img(path=path, resize_func=resize_func, size=size, for_all=for_all)\n",
    "#         img_cnn = None\n",
    "#         if model_CNN:\n",
    "#             img_cnn = read_img(path=path, resize_func=resize_add_border, size=(600, 600))\n",
    "#         pred_score = predict(img_mg, img_cnn, model_gap, model, model_CNN, is_norm)\n",
    "#         if np.argmax(pred_score) != label:\n",
    "#             false_pred.append(path)\n",
    "            \n",
    "#         predicted.append(pred_score)\n",
    "    \n",
    "#     predicted = np.array(predicted)\n",
    "#     predicted = np.squeeze(predicted)\n",
    "    \n",
    "#     if save_results:\n",
    "#         np.save(save_to, np.argmax(predicted, axis=-1))\n",
    "        \n",
    "#     return predicted, false_pred"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3761c774",
   "metadata": {},
   "source": [
    "## Saparating false predicted images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cdffc854",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted, false_pred = predict_from_path_false_pred(model, paths_bench, resize_func=resize_max, \n",
    "                              size=(996, 996), model_CNN=model_cnn, is_norm=False)# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019da9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f27d29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# url = f'{root_path}Data/benchmark/images/bad/2022-02-20-11-24-fortress-7024370_1280.jpg'\n",
    "# url = false_pred_1[0]\n",
    "\n",
    "def read_and_transform_img(url):\n",
    "    img = Image.open(url)\n",
    "    img = img_to_array(img)\n",
    "#     img = img / 255\n",
    "#     img = resize_max(img, size=(996,996))\n",
    "    print(img.shape)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "\n",
    "    return img\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d01205c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the paths for the trained FC, WITH normalization during validation\n",
    "acc = calc_acc(labels_bench, predicted1)\n",
    "print(f'Accuracy: {acc}')\n",
    "for path in false_pred_1:\n",
    "    print(path)\n",
    "len(false_pred_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbbc3f82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1079, 894, 3)\n",
      "<class 'numpy.ndarray'>\n",
      "image shape (None, 1079, 894, 3)\n",
      "Resize max (1079, 894, 3)\n",
      "image shape after resize max (1, 996, 825, 3)\n",
      "mg feature vector shape (1, 16928)\n",
      "image shape after resize border (1, 600, 600, 3)\n",
      "cnn feature vector shape (None, 2560)\n",
      "mg feature vector shape after pca (1, 8464)\n",
      "cnn feature vector shape after pca (None, 1280)\n",
      "feature vector shape after concat (1, 9744)\n",
      "feature vector shape after fc (1, 2)\n",
      "print before return\n"
     ]
    }
   ],
   "source": [
    "path = \"XAI/gal-angebot-portrait-1.jpg\"\n",
    "\n",
    "images = read_and_transform_img(path)\n",
    "print(type(images))\n",
    "preds = model.predict(images)\n",
    "prediction = np.argmax(preds)\n",
    "pct = np.max(preds)\n",
    "if prediction == 0:\n",
    "    print('It\\'s no aesthethic!')\n",
    "elif prediction == 1:\n",
    "    print('It\\'s an aesthethic!')\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c6ec55a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1079, 894, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8306c889",
   "metadata": {},
   "source": [
    "## Explanation for false predictions with SHAP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f201fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "masker = shap.maskers.Image(\"blur\"+ str(images.shape[1:3]), images.shape[1:]) #\"blur\"+ str(images.shape[1:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbab534a",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.Explainer(model, masker, output_names=[0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e23452",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values = explainer(images, max_evals = 1000, batch_size = 1, outputs = shap.Explanation.argsort.flip[:2])\n",
    "shap.image_plot(shap_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4e1778",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
