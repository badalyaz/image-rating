{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a68d025",
   "metadata": {},
   "outputs": [],
   "source": [
    "from final_utils import *\n",
    "from Sufflenet_CNN_FC import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1b60bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = generate_root_path()\n",
    "SC_CE_KLD = tf.keras.losses.SparseCategoricalCrossentropy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "deac32fd",
   "metadata": {},
   "source": [
    "### DataLoader and other nesseccary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86fb85b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_accuracy(y_true, y_pred): \n",
    "    return ((tf.math.argmax(y_pred, axis=1)) == tf.cast(y_true, dtype=tf.dtypes.int64)).numpy().mean()\n",
    "\n",
    "def lr_exp_decay(epoch, lr):\n",
    "    k = 0.04\n",
    "    return lr * np.exp(-k*epoch)\n",
    "\n",
    "def data_loader_connected(data, labels, resize_func=None, size=None):\n",
    "    #big pictures require lots of computational data, so we resize them\n",
    "    images = []\n",
    "    count = 0\n",
    "    for i,path in enumerate(data):\n",
    "        try:\n",
    "            img = Image.open(path).convert('RGB')\n",
    "            img_tensor = tf.keras.utils.img_to_array(img)\n",
    "            img_tensor = img_tensor / 255\n",
    "            if resize_func:\n",
    "                img_tensor = resize_func(img_tensor, size=size)\n",
    "            images.append(img_tensor)\n",
    "        except:\n",
    "            print('Skip')\n",
    "            labels = np.delete(labels, i - count)\n",
    "            count += 1\n",
    "            \n",
    "    images = tf.stack(images)\n",
    "    \n",
    "    return images, labels"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bd814f3b",
   "metadata": {},
   "source": [
    "### Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e096aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainer(model, data, data_val, batch_size=16, epochs=20, learning_rate=0.003, save_to=None):\n",
    "    X_train, y_train = data\n",
    "    X_train, y_train = data_loader_connected(X_train, y_train)\n",
    "    print(X_train.shape)\n",
    "    print(y_train.shape)\n",
    "    \n",
    "    model.compile(loss=SC_CE_KLD,\n",
    "                  optimizer=keras.optimizers.Adam(learning_rate=learning_rate, beta_1=0.9, beta_2=0.999, \n",
    "                                                  epsilon=1e-07, decay=0, amsgrad=False))\n",
    "    \n",
    "    schedule = tf.keras.callbacks.LearningRateScheduler(lr_exp_decay, verbose=0)\n",
    "    callbacks_list = [schedule]\n",
    "\n",
    "    history = model.fit(\n",
    "                    X_train, \n",
    "                    y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    validation_data = data_val,\n",
    "                    callbacks=callbacks_list,\n",
    "                    verbose=1\n",
    "                )\n",
    "    \n",
    "    print('Done')\n",
    "    return history"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d894e5c7",
   "metadata": {},
   "source": [
    "### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee2f61a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_path = main_path=f'{root_path}Data/splitted/train/'\n",
    "paths_bad = []\n",
    "paths_good = []\n",
    "    \n",
    "for i in range(7):\n",
    "    alm_train_bad = open(f'{main_path}data_bad{i+1}.json')\n",
    "    bad_data = json.load(alm_train_bad)\n",
    "    \n",
    "    for data in bad_data:\n",
    "        path_to_img = main_path + f'images/{data[\"label\"]}/{data[\"splitted\"]}_resized_600x600/' + data['name']\n",
    "        paths_bad.append(path_to_img)\n",
    "        \n",
    "alm_train_good = open(f'{main_path}/data_good1.json')\n",
    "good_data = json.load(alm_train_good)\n",
    "for data in good_data:\n",
    "    path_to_img = main_path + f'images/{data[\"label\"]}/{data[\"splitted\"]}_resized_600x600/' + data['name']\n",
    "    paths_good.append(path_to_img)\n",
    "    \n",
    "for i in range(7):\n",
    "    paths_bad[i] = np.squeeze(np.array(paths_bad[i]))\n",
    "paths_good = np.squeeze(np.array(paths_good))\n",
    "   \n",
    "# Generating static validation data\n",
    "paths_bad, paths_bad_val = extract_static_val_data(paths_bad, perc = 0.0009) #original - 0.017\n",
    "paths_good, paths_good_val = extract_static_val_data(paths_good, perc = 0.005) #original - 0.11\n",
    "\n",
    "paths_bad = np.array(paths_bad)\n",
    "paths_good = np.array(paths_good)\n",
    "paths_bad_val = np.array(paths_bad_val)\n",
    "paths_good_val = np.array(paths_good_val)\n",
    "labels_good = np.ones(len(paths_good))\n",
    "labels_bad = np.zeros(len(paths_bad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ae74d8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(152546,)\n",
      "(152546,)\n"
     ]
    }
   ],
   "source": [
    "full_data = np.concatenate((np.repeat(paths_good, 7), paths_bad))\n",
    "full_labels = np.concatenate(((np.repeat(labels_good, 7), labels_bad)))   \n",
    "\n",
    "#shuffling\n",
    "idx = np.random.permutation(len(full_data))\n",
    "full_data = full_data[idx]\n",
    "print(full_data.shape)\n",
    "print(full_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f17ebb84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting data \n",
    "split_factor = 8\n",
    "splitted_data = []\n",
    "splitted_labels = []\n",
    "\n",
    "global_batches = int(full_data.shape[0] / split_factor)\n",
    "for i in range(global_batches):\n",
    "    batch_data = full_data[i*split_factor: (i+1)*split_factor]\n",
    "    batch_labels = full_labels[i*split_factor: (i+1)*split_factor]\n",
    "    \n",
    "    splitted_labels.append(batch_labels)\n",
    "    splitted_data.append(batch_data)\n",
    "    \n",
    "\n",
    "splitted_data[-1] = np.concatenate((splitted_data[-1], full_data[len(splitted_data)*split_factor:]))\n",
    "splitted_labels[-1] = np.concatenate((splitted_labels[-1], full_labels[len(splitted_labels)*split_factor:]))\n",
    "\n",
    "data = splitted_data, splitted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e3181de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading validation data\n",
    "paths_val = np.concatenate((paths_bad_val, paths_good_val ), axis=0 )\n",
    "val_labels = np.concatenate((np.zeros(len(paths_bad_val)), np.ones(len(paths_good_val))))\n",
    "X_val, y_val = data_loader_connected(paths_val, val_labels)\n",
    "\n",
    "data_val = (X_val, y_val)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fb97b523",
   "metadata": {},
   "source": [
    "### Creating model and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0455249",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "epochs = 10\n",
    "learning_rate = 0.003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "53cbc7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Connected()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "38eb22f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = tf.random.uniform((1, 600, 600, 3))\n",
    "# model.build([1, 600, 600, 3])\n",
    "# model.predict(x, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3e379b50",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started\n",
      "(8, 600, 600, 3)\n",
      "(8,)\n",
      "Epoch 1/10\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0475"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\CareAware\\.conda\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1557, in test_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\CareAware\\.conda\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1546, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\CareAware\\.conda\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1535, in run_step  **\n        outputs = model.test_step(data)\n    File \"C:\\Users\\CareAware\\.conda\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1499, in test_step\n        y_pred = self(x, training=False)\n    File \"C:\\Users\\CareAware\\.conda\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\CAREAW~1\\AppData\\Local\\Temp\\__autograph_generated_filef8m_38us.py\", line 10, in tf__call\n        x1 = ag__.converted_call(ag__.ld(self).layer_shufflenet, (ag__.ld(img),), None, fscope)\n    File \"C:\\Users\\CAREAW~1\\AppData\\Local\\Temp\\__autograph_generated_filebusy1nc4.py\", line 14, in tf__call\n        x = ag__.converted_call(ag__.ld(self).block1, (ag__.ld(x),), None, fscope)\n    File \"C:\\Users\\CAREAW~1\\AppData\\Local\\Temp\\__autograph_generated_filezpoyw4ir.py\", line 40, in tf__call\n        ag__.for_stmt(ag__.converted_call(ag__.ld(range), (2, ag__.ld(self).num_units + 1), None, fscope), None, loop_body, get_state, set_state, ('x', 'y', 'basic_uint_count'), {'iterate_names': 'j'})\n    File \"C:\\Users\\CAREAW~1\\AppData\\Local\\Temp\\__autograph_generated_filezpoyw4ir.py\", line 35, in loop_body\n        (x, y) = ag__.converted_call(ag__.ld(self).shuffle_xy, (ag__.ld(x), ag__.ld(y)), None, fscope)\n    File \"C:\\Users\\CAREAW~1\\AppData\\Local\\Temp\\__autograph_generated_filewnbn4oln.py\", line 14, in tf__shuffle_xy\n        z = ag__.converted_call(ag__.ld(tf).reshape, (ag__.ld(z), [ag__.ld(batch_size), ag__.ld(height), ag__.ld(width), 2 * ag__.ld(depth)]), None, fscope)\n\n    TypeError: Exception encountered when calling layer \"connected\" (type Connected).\n    \n    in user code:\n    \n        File \"C:\\Users\\CareAware\\Consulting_Projects\\aesthetic-ai\\DeepFL\\DeepFL_binary\\Sufflenet_CNN_FC.py\", line 21, in call  *\n            x1 = self.layer_shufflenet(img)\n        File \"C:\\Users\\CareAware\\.conda\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler  **\n            raise e.with_traceback(filtered_tb) from None\n        File \"C:\\Users\\CAREAW~1\\AppData\\Local\\Temp\\__autograph_generated_filebusy1nc4.py\", line 14, in tf__call\n            x = ag__.converted_call(ag__.ld(self).block1, (ag__.ld(x),), None, fscope)\n        File \"C:\\Users\\CAREAW~1\\AppData\\Local\\Temp\\__autograph_generated_filezpoyw4ir.py\", line 40, in tf__call\n            ag__.for_stmt(ag__.converted_call(ag__.ld(range), (2, ag__.ld(self).num_units + 1), None, fscope), None, loop_body, get_state, set_state, ('x', 'y', 'basic_uint_count'), {'iterate_names': 'j'})\n        File \"C:\\Users\\CAREAW~1\\AppData\\Local\\Temp\\__autograph_generated_filezpoyw4ir.py\", line 35, in loop_body\n            (x, y) = ag__.converted_call(ag__.ld(self).shuffle_xy, (ag__.ld(x), ag__.ld(y)), None, fscope)\n        File \"C:\\Users\\CAREAW~1\\AppData\\Local\\Temp\\__autograph_generated_filewnbn4oln.py\", line 14, in tf__shuffle_xy\n            z = ag__.converted_call(ag__.ld(tf).reshape, (ag__.ld(z), [ag__.ld(batch_size), ag__.ld(height), ag__.ld(width), 2 * ag__.ld(depth)]), None, fscope)\n    \n        TypeError: Exception encountered when calling layer \"shufflenet_v2\" (type ShufflenetV2).\n        \n        in user code:\n        \n            File \"C:\\Users\\CareAware\\Consulting_Projects\\aesthetic-ai\\DeepFL\\DeepFL_binary\\shufflenetV2_tf2.py\", line 46, in call  *\n                x = self.block1(x)\n            File \"C:\\Users\\CareAware\\.conda\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler  **\n                raise e.with_traceback(filtered_tb) from None\n            File \"C:\\Users\\CAREAW~1\\AppData\\Local\\Temp\\__autograph_generated_filezpoyw4ir.py\", line 40, in tf__call\n                ag__.for_stmt(ag__.converted_call(ag__.ld(range), (2, ag__.ld(self).num_units + 1), None, fscope), None, loop_body, get_state, set_state, ('x', 'y', 'basic_uint_count'), {'iterate_names': 'j'})\n            File \"C:\\Users\\CAREAW~1\\AppData\\Local\\Temp\\__autograph_generated_filezpoyw4ir.py\", line 35, in loop_body\n                (x, y) = ag__.converted_call(ag__.ld(self).shuffle_xy, (ag__.ld(x), ag__.ld(y)), None, fscope)\n            File \"C:\\Users\\CAREAW~1\\AppData\\Local\\Temp\\__autograph_generated_filewnbn4oln.py\", line 14, in tf__shuffle_xy\n                z = ag__.converted_call(ag__.ld(tf).reshape, (ag__.ld(z), [ag__.ld(batch_size), ag__.ld(height), ag__.ld(width), 2 * ag__.ld(depth)]), None, fscope)\n        \n            TypeError: Exception encountered when calling layer \"shuffle_block\" (type ShuffleBlock).\n            \n            in user code:\n            \n                File \"C:\\Users\\CareAware\\Consulting_Projects\\aesthetic-ai\\DeepFL\\DeepFL_binary\\shufflenetV2_tf2.py\", line 124, in call  *\n                    x, y = self.shuffle_xy(x, y)\n                File \"C:\\Users\\CareAware\\Consulting_Projects\\aesthetic-ai\\DeepFL\\DeepFL_binary\\shufflenetV2_tf2.py\", line 98, in shuffle_xy  *\n                    z = tf.reshape(z, [batch_size, height, width, 2*depth])\n            \n                TypeError: Failed to convert elements of [None, 75, 75, 26] to Tensor. Consider casting elements to a supported type. See https://www.tensorflow.org/api_docs/python/tf/dtypes for supported TF dtypes.\n            \n            \n            Call arguments received by layer \"shuffle_block\" (type ShuffleBlock):\n              • x=tf.Tensor(shape=(None, 150, 150, 24), dtype=float32)\n        \n        \n        Call arguments received by layer \"shufflenet_v2\" (type ShufflenetV2):\n          • img=tf.Tensor(shape=(None, 600, 600, 3), dtype=float32)\n    \n    \n    Call arguments received by layer \"connected\" (type Connected):\n      • img=tf.Tensor(shape=(None, 600, 600, 3), dtype=float32)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(data)):\n\u001b[0;32m      3\u001b[0m     batch_data \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;241m0\u001b[39m][i], data[\u001b[38;5;241m1\u001b[39m][i]\n\u001b[1;32m----> 4\u001b[0m     history \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mbatch_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mdata_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlearning_rate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m     model\u001b[38;5;241m.\u001b[39msave_weights(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodels/ShuffleNet_CNN_FC/Connected_on_600x600\u001b[39m\u001b[38;5;124m'\u001b[39m, save_format\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtf\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m batch_data\n",
      "Input \u001b[1;32mIn [4]\u001b[0m, in \u001b[0;36mtrainer\u001b[1;34m(model, data, data_val, batch_size, epochs, learning_rate, save_to)\u001b[0m\n\u001b[0;32m     11\u001b[0m schedule \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mLearningRateScheduler(lr_exp_decay, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     12\u001b[0m callbacks_list \u001b[38;5;241m=\u001b[39m [schedule]\n\u001b[1;32m---> 14\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m                \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m                \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m                \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m                \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m                \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdata_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m                \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m                \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[0;32m     22\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDone\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m history\n",
      "File \u001b[1;32m~\\.conda\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mC:\\Users\\CAREAW~1\\AppData\\Local\\Temp\\__autograph_generated_fileupwxps13.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__test_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Users\\CAREAW~1\\AppData\\Local\\Temp\\__autograph_generated_filef8m_38us.py:10\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m      8\u001b[0m do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m      9\u001b[0m retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mUndefinedReturnValue()\n\u001b[1;32m---> 10\u001b[0m x1 \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mlayer_shufflenet, (ag__\u001b[38;5;241m.\u001b[39mld(img),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     11\u001b[0m x2 \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mlayer_cnn, (ag__\u001b[38;5;241m.\u001b[39mld(img),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     12\u001b[0m x \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mconcat, ([ag__\u001b[38;5;241m.\u001b[39mld(x1), ag__\u001b[38;5;241m.\u001b[39mld(x2)],), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n",
      "File \u001b[1;32mC:\\Users\\CAREAW~1\\AppData\\Local\\Temp\\__autograph_generated_filebusy1nc4.py:14\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m     12\u001b[0m x \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mact1, (ag__\u001b[38;5;241m.\u001b[39mld(x),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     13\u001b[0m x \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mmaxpool1, (ag__\u001b[38;5;241m.\u001b[39mld(x),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m---> 14\u001b[0m x \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mblock1, (ag__\u001b[38;5;241m.\u001b[39mld(x),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     15\u001b[0m x \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mblock2, (ag__\u001b[38;5;241m.\u001b[39mld(x),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m x \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mblock3, (ag__\u001b[38;5;241m.\u001b[39mld(x),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n",
      "File \u001b[1;32mC:\\Users\\CAREAW~1\\AppData\\Local\\Temp\\__autograph_generated_filezpoyw4ir.py:40\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     38\u001b[0m     basic_uint_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     39\u001b[0m j \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mUndefined(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mj\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 40\u001b[0m ag__\u001b[38;5;241m.\u001b[39mfor_stmt(ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mrange\u001b[39m), (\u001b[38;5;241m2\u001b[39m, ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mnum_units \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m), \u001b[38;5;28;01mNone\u001b[39;00m, fscope), \u001b[38;5;28;01mNone\u001b[39;00m, loop_body, get_state, set_state, (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbasic_uint_count\u001b[39m\u001b[38;5;124m'\u001b[39m), {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124miterate_names\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mj\u001b[39m\u001b[38;5;124m'\u001b[39m})\n\u001b[0;32m     41\u001b[0m x \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(layers)\u001b[38;5;241m.\u001b[39mconcatenate, ([ag__\u001b[38;5;241m.\u001b[39mld(x), ag__\u001b[38;5;241m.\u001b[39mld(y)],), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mC:\\Users\\CAREAW~1\\AppData\\Local\\Temp\\__autograph_generated_filezpoyw4ir.py:35\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call.<locals>.loop_body\u001b[1;34m(itr)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mnonlocal\u001b[39;00m basic_uint_count, y, x\n\u001b[0;32m     34\u001b[0m j \u001b[38;5;241m=\u001b[39m itr\n\u001b[1;32m---> 35\u001b[0m (x, y) \u001b[38;5;241m=\u001b[39m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshuffle_xy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     36\u001b[0m x \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mall_basic_uint[ag__\u001b[38;5;241m.\u001b[39mld(basic_uint_count)], (ag__\u001b[38;5;241m.\u001b[39mld(x),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     37\u001b[0m basic_uint_count \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mld(basic_uint_count)\n",
      "File \u001b[1;32mC:\\Users\\CAREAW~1\\AppData\\Local\\Temp\\__autograph_generated_filewnbn4oln.py:14\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__shuffle_xy\u001b[1;34m(self, x, y)\u001b[0m\n\u001b[0;32m     12\u001b[0m z \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mstack, ([ag__\u001b[38;5;241m.\u001b[39mld(x), ag__\u001b[38;5;241m.\u001b[39mld(y)],), \u001b[38;5;28mdict\u001b[39m(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m), fscope)\n\u001b[0;32m     13\u001b[0m z \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mtranspose, (ag__\u001b[38;5;241m.\u001b[39mld(z), [\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m3\u001b[39m]), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m---> 14\u001b[0m z \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mreshape, (ag__\u001b[38;5;241m.\u001b[39mld(z), [ag__\u001b[38;5;241m.\u001b[39mld(batch_size), ag__\u001b[38;5;241m.\u001b[39mld(height), ag__\u001b[38;5;241m.\u001b[39mld(width), \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m ag__\u001b[38;5;241m.\u001b[39mld(depth)]), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     15\u001b[0m (x, y) \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39msplit, (ag__\u001b[38;5;241m.\u001b[39mld(z),), \u001b[38;5;28mdict\u001b[39m(num_or_size_splits\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m), fscope)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;31mTypeError\u001b[0m: in user code:\n\n    File \"C:\\Users\\CareAware\\.conda\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1557, in test_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\CareAware\\.conda\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1546, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\CareAware\\.conda\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1535, in run_step  **\n        outputs = model.test_step(data)\n    File \"C:\\Users\\CareAware\\.conda\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1499, in test_step\n        y_pred = self(x, training=False)\n    File \"C:\\Users\\CareAware\\.conda\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\CAREAW~1\\AppData\\Local\\Temp\\__autograph_generated_filef8m_38us.py\", line 10, in tf__call\n        x1 = ag__.converted_call(ag__.ld(self).layer_shufflenet, (ag__.ld(img),), None, fscope)\n    File \"C:\\Users\\CAREAW~1\\AppData\\Local\\Temp\\__autograph_generated_filebusy1nc4.py\", line 14, in tf__call\n        x = ag__.converted_call(ag__.ld(self).block1, (ag__.ld(x),), None, fscope)\n    File \"C:\\Users\\CAREAW~1\\AppData\\Local\\Temp\\__autograph_generated_filezpoyw4ir.py\", line 40, in tf__call\n        ag__.for_stmt(ag__.converted_call(ag__.ld(range), (2, ag__.ld(self).num_units + 1), None, fscope), None, loop_body, get_state, set_state, ('x', 'y', 'basic_uint_count'), {'iterate_names': 'j'})\n    File \"C:\\Users\\CAREAW~1\\AppData\\Local\\Temp\\__autograph_generated_filezpoyw4ir.py\", line 35, in loop_body\n        (x, y) = ag__.converted_call(ag__.ld(self).shuffle_xy, (ag__.ld(x), ag__.ld(y)), None, fscope)\n    File \"C:\\Users\\CAREAW~1\\AppData\\Local\\Temp\\__autograph_generated_filewnbn4oln.py\", line 14, in tf__shuffle_xy\n        z = ag__.converted_call(ag__.ld(tf).reshape, (ag__.ld(z), [ag__.ld(batch_size), ag__.ld(height), ag__.ld(width), 2 * ag__.ld(depth)]), None, fscope)\n\n    TypeError: Exception encountered when calling layer \"connected\" (type Connected).\n    \n    in user code:\n    \n        File \"C:\\Users\\CareAware\\Consulting_Projects\\aesthetic-ai\\DeepFL\\DeepFL_binary\\Sufflenet_CNN_FC.py\", line 21, in call  *\n            x1 = self.layer_shufflenet(img)\n        File \"C:\\Users\\CareAware\\.conda\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler  **\n            raise e.with_traceback(filtered_tb) from None\n        File \"C:\\Users\\CAREAW~1\\AppData\\Local\\Temp\\__autograph_generated_filebusy1nc4.py\", line 14, in tf__call\n            x = ag__.converted_call(ag__.ld(self).block1, (ag__.ld(x),), None, fscope)\n        File \"C:\\Users\\CAREAW~1\\AppData\\Local\\Temp\\__autograph_generated_filezpoyw4ir.py\", line 40, in tf__call\n            ag__.for_stmt(ag__.converted_call(ag__.ld(range), (2, ag__.ld(self).num_units + 1), None, fscope), None, loop_body, get_state, set_state, ('x', 'y', 'basic_uint_count'), {'iterate_names': 'j'})\n        File \"C:\\Users\\CAREAW~1\\AppData\\Local\\Temp\\__autograph_generated_filezpoyw4ir.py\", line 35, in loop_body\n            (x, y) = ag__.converted_call(ag__.ld(self).shuffle_xy, (ag__.ld(x), ag__.ld(y)), None, fscope)\n        File \"C:\\Users\\CAREAW~1\\AppData\\Local\\Temp\\__autograph_generated_filewnbn4oln.py\", line 14, in tf__shuffle_xy\n            z = ag__.converted_call(ag__.ld(tf).reshape, (ag__.ld(z), [ag__.ld(batch_size), ag__.ld(height), ag__.ld(width), 2 * ag__.ld(depth)]), None, fscope)\n    \n        TypeError: Exception encountered when calling layer \"shufflenet_v2\" (type ShufflenetV2).\n        \n        in user code:\n        \n            File \"C:\\Users\\CareAware\\Consulting_Projects\\aesthetic-ai\\DeepFL\\DeepFL_binary\\shufflenetV2_tf2.py\", line 46, in call  *\n                x = self.block1(x)\n            File \"C:\\Users\\CareAware\\.conda\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler  **\n                raise e.with_traceback(filtered_tb) from None\n            File \"C:\\Users\\CAREAW~1\\AppData\\Local\\Temp\\__autograph_generated_filezpoyw4ir.py\", line 40, in tf__call\n                ag__.for_stmt(ag__.converted_call(ag__.ld(range), (2, ag__.ld(self).num_units + 1), None, fscope), None, loop_body, get_state, set_state, ('x', 'y', 'basic_uint_count'), {'iterate_names': 'j'})\n            File \"C:\\Users\\CAREAW~1\\AppData\\Local\\Temp\\__autograph_generated_filezpoyw4ir.py\", line 35, in loop_body\n                (x, y) = ag__.converted_call(ag__.ld(self).shuffle_xy, (ag__.ld(x), ag__.ld(y)), None, fscope)\n            File \"C:\\Users\\CAREAW~1\\AppData\\Local\\Temp\\__autograph_generated_filewnbn4oln.py\", line 14, in tf__shuffle_xy\n                z = ag__.converted_call(ag__.ld(tf).reshape, (ag__.ld(z), [ag__.ld(batch_size), ag__.ld(height), ag__.ld(width), 2 * ag__.ld(depth)]), None, fscope)\n        \n            TypeError: Exception encountered when calling layer \"shuffle_block\" (type ShuffleBlock).\n            \n            in user code:\n            \n                File \"C:\\Users\\CareAware\\Consulting_Projects\\aesthetic-ai\\DeepFL\\DeepFL_binary\\shufflenetV2_tf2.py\", line 124, in call  *\n                    x, y = self.shuffle_xy(x, y)\n                File \"C:\\Users\\CareAware\\Consulting_Projects\\aesthetic-ai\\DeepFL\\DeepFL_binary\\shufflenetV2_tf2.py\", line 98, in shuffle_xy  *\n                    z = tf.reshape(z, [batch_size, height, width, 2*depth])\n            \n                TypeError: Failed to convert elements of [None, 75, 75, 26] to Tensor. Consider casting elements to a supported type. See https://www.tensorflow.org/api_docs/python/tf/dtypes for supported TF dtypes.\n            \n            \n            Call arguments received by layer \"shuffle_block\" (type ShuffleBlock):\n              • x=tf.Tensor(shape=(None, 150, 150, 24), dtype=float32)\n        \n        \n        Call arguments received by layer \"shufflenet_v2\" (type ShufflenetV2):\n          • img=tf.Tensor(shape=(None, 600, 600, 3), dtype=float32)\n    \n    \n    Call arguments received by layer \"connected\" (type Connected):\n      • img=tf.Tensor(shape=(None, 600, 600, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print('Training started')\n",
    "for i in range(len(data)):\n",
    "    batch_data = data[0][i], data[1][i]\n",
    "    history = trainer(model, \n",
    "                      batch_data, \n",
    "                      data_val,\n",
    "                      batch_size=batch_size,\n",
    "                      epochs=epochs, \n",
    "                      learning_rate=learning_rate)\n",
    "    model.save_weights(f'models/ShuffleNet_CNN_FC/Connected_on_600x600', save_format='tf')\n",
    "    \n",
    "    del batch_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c34982f2",
   "metadata": {},
   "source": [
    "### Training on dummy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad3b3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_data = tf.random.uniform((64, 600, 600, 3))\n",
    "labels = np.random.randint(0,1,(64, 16928))\n",
    "data = img_data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd38cca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_data = tf.random.uniform((4, 600, 600, 3))\n",
    "labels = np.random.randint(0,1,(4, 16928))\n",
    "data_val = img_data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6e54f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6295726",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = tf.convert_to_tensor(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e456387f",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(img_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b858bf60",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = trainer(model, \n",
    "                  data, \n",
    "                  weights_path,\n",
    "                  data_val,\n",
    "                  batch_size=batch_size,\n",
    "                  epochs=epochs, \n",
    "                  learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da50bbd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
